{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "### ★ Import Libraries\n",
    "#### What is a Library?\n",
    "A library is a tool used to do a specific job\n",
    "\n",
    "#### 3 Essential libraries:\n",
    "1. **Numpy:** contains mathematical tools.\n",
    "2. **Matplotlib - Pyplot(sub-library):** plots charts.\n",
    "3. **Pandas:** best library to import & manage data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Import Data Sets\n",
    "* Set a working directory before importing data sets.\n",
    "* Use the library, Pandas to import data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Create Matrix of Features & Dependent Variable Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values    #rows[0:x], col[0:y-1]\n",
    "y = dataset.iloc[:, 3].values      #rows[0:x], col[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Take Care of Missing Data\n",
    "* Data can have missing values for a number of reasons (ie. not recorded observations, data corruption, etc.)\n",
    "* Handling missing data is important as many ML algorithms do not support data with missing values.\n",
    "* Use the Imputer from the Scikit-learn library\n",
    "* Select the word Imputer + `Ctrl + i` to view the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Encode Categorical Variables into numbers\n",
    "* Categorical Data: variables that contain label values rather than numerical values.\n",
    "* Most ML algorithms cannot operate on label data directly & require all input & output variables to be numeric.\n",
    "* Two steps to convert Categorical Data to Numerical Data:\n",
    "\t1. Integer Encoding\n",
    "\t\t- each unique category value is assigned an integer value\n",
    "\t\tExample:\n",
    "        ```\n",
    "        Red = 0\n",
    "        Blue = 1\n",
    "        Green = 2\n",
    "        ```\n",
    "\t2. One-Hot Encoding\n",
    "\t\t- When there's no ordinal relationship, integer encoding is not enough.\n",
    "\t\t- integer encoded variable is removed and a new binary variable is added for each unique integer value\n",
    "\t\t- the binary variables are often called dummy variables\n",
    "\t\tExample:\n",
    "        ```\n",
    "        red\t\tblue\t\tgreen\n",
    "         1\t\t 0\t\t\t  0\n",
    "         0\t\t 1\t\t\t  0\n",
    "         0\t\t 0\t\t\t  1\n",
    "        ```\n",
    "* Use the LabelEncoder & OneHotEncoder modules from the Scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_country = LabelEncoder()\n",
    "X[:, 0] = labelencoder_country.fit_transform(X[:, 0])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "labelencoder_purchased = LabelEncoder()\n",
    "y = labelencoder_purchased.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Split the dataset into Training set & Test set\n",
    "* Training set: dataset of examples used for learning, to fit the parameters of a classifier/algorithm.\n",
    "* Test set: set of examples used only to assess the performance of a classifier.\n",
    "* It is recommended to split the dataset to a 8:2 ratio (training:test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Feature Scaling\n",
    "* method used to standardize the range of independent variables or features of data.\n",
    "* Some methods used:\n",
    "\t1. Standardization\n",
    "\n",
    "\t\t$$\n",
    "\t\t x_{s} = \\frac{x - mean(x)} {standard deviation(x)}\n",
    "\t\t$$\n",
    "\n",
    "\t2. Normalization\n",
    "\n",
    "\t\t$$\n",
    "        x_{n} = \\frac{x - min(x)} {max(x) - min(x)}\n",
    "        $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_sc = StandardScaler()\n",
    "X_train = X_sc.fit_transform(X_train)\n",
    "X_test = X_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Difference between fit and fit_transform:\n",
    "\t- **fit** calculates the mean & variance from the values in X_train\n",
    "\t- **transform** transforms all of the features by subtracting the mean from the the values in X_train & dividing it by the variance.\n",
    "\t- You  fit the scaler using only the training data so that there will be no bias in your model with information from the test data.\n",
    "\t- you only want to transform the test data by using the parameters(mean & variance) computed on the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
